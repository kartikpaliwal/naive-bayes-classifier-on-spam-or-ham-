{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here is the naive bayes classifier on a data set by kaggle in which classification of spam mail or ham mail is done\n",
    "with the help of conditional probability and likelihood of that mail to be spam or ham is calculated and then compared.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests  \n",
    "import io\n",
    "url  = \"https://raw.githubusercontent.com/kartikpaliwal/naive-bayes-classifier-on-spam-or-ham-/master/spamraw.csv\"\n",
    "s=requests.get(url).content\n",
    "alLdatA=pd.read_csv(io.StringIO(s.decode('utf-8')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here i have divided the data set in 2 parts\n",
    "traiNdatA = alLdatA[0:(int(0.60*(len(alLdatA))))]\n",
    "tesTdatA = alLdatA[(int(0.60*(len(alLdatA)))):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here i divided spam mail and ham mail\n",
    "spaM = []\n",
    "haM = []\n",
    "for e  in range(len(traiNdatA)):\n",
    "    if traiNdatA.type[e] == 'spam':\n",
    "        spaM.append(traiNdatA.iloc[e].text)\n",
    "    else:\n",
    "        haM.append(traiNdatA.iloc[e].text)  \n",
    "        \n",
    "#Here is the individual probability of spam and ham sentence \n",
    "PoFspaMwordS = (len(spaM)/(len(spaM)+len(haM)))\n",
    "PoFhaMwordS = (len(haM)/(len(spaM)+len(haM)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here i have saperated the data by words of spam and ham\n",
    "spaMworD = []\n",
    "haMworD = []\n",
    "for r in range(len(spaM)):\n",
    "    spaMworD.extend(set(((spaM[r]).replace(\")\", \"\").replace(\"(\", \"\")).split(\" \")))\n",
    "for r in range(len(haM)):\n",
    "    haMworD.extend(set((haM[r]).split(\" \")))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted the words\n",
    "spaMworD = sorted(spaMworD)  \n",
    "haMworD = sorted(haMworD) \n",
    "\n",
    "##+++++++++++++++++++++===============\n",
    "#Here i am counting the no. of times a word is repeating\n",
    "##---------------------===============\n",
    "counTS = []\n",
    "count = 0\n",
    "for i in range((len(spaMworD))-1):\n",
    "    if spaMworD[i]==spaMworD[i+1]:\n",
    "        count+=1 \n",
    "    else:\n",
    "        counTS.append(count)  \n",
    "        count = 0\n",
    "\n",
    "counTH = []\n",
    "count = 0\n",
    "for i in range((len(haMworD))-1):\n",
    "    if haMworD[i]==haMworD[i+1]:\n",
    "        count+=1 \n",
    "    else:\n",
    "        counTH.append(count)  \n",
    "        count = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#++++++++++++HERE THE WORDS ARE TAKEN AS A LIST BUT WITHOUT repeating.++++++++++++++++\n",
    "\n",
    "wordS = set(spaMworD)   \n",
    "wordH = set(haMworD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here i made a dictionary of spam and ham words\n",
    "spaMdicT = dict(zip(wordS, counTS))\n",
    "haMdicT = dict(zip(wordH, counTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kartik\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Here i have taken off label from test data as it is supervised learning\n",
    "TypeTestData = list(tesTdatA.type)\n",
    "tesTdatA.drop(['type'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestDataSplit = []\n",
    "for r in range(len(tesTdatA)-1):\n",
    "    TestDataSplit.append(list(set(((tesTdatA.text[r+3335]).replace(\"(\", \"\").replace(\")\", \"\")).split(\" \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we will be comparing the probability of 2 classes i removed marginal probability that comes in denominator\n",
    "#in both cases so in order to optimize code and its speed i removed dr that was coming in both probability>>>>>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the main math part of my code \n",
    "#--ONLY FOR STRONG HEART---------#\n",
    "PofHam = []\n",
    "PofSpam = []\n",
    "for r in TestDataSplit:\n",
    "    SpamWords = 1\n",
    "    HamWords  = 1\n",
    "    for j in r:\n",
    "        if (list(spaMdicT).count(j)) > 0  and ((list(haMdicT).count(j)) > 0): \n",
    "            SpamWords = SpamWords*(((spaMdicT[j])/len(spaMdicT))+1)\n",
    "            HamWords = HamWords*(((haMdicT[j])/len(haMdicT))+1)\n",
    "        else:\n",
    "            SpamWords = SpamWords*(((1)/len(spaMdicT))+1)\n",
    "            HamWords = HamWords*(((1)/len(haMdicT))+1)\n",
    "    PofSpam.append(PoFspaMwordS*(np.log(SpamWords)))\n",
    "    PofHam.append(PoFhaMwordS*(np.log(HamWords)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []    #fINAL ARRAY OF RESULTS \n",
    "for i in range(len(TestDataSplit)):\n",
    "    if PofHam > PofSpam:\n",
    "        result.append('ham')\n",
    "    else:\n",
    "        result.append('spam')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches =0 \n",
    "for i in range(len(TestDataSplit)):\n",
    "    if TypeTestData[i] == result[i]:\n",
    "        matches+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (matches/len(TestDataSplit))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.18983355825462\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#That's an awesome accuracy just by playing with probability and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
